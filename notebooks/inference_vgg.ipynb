{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "S30omt-UnCr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/image_classification_course"
      ],
      "metadata": {
        "id": "_xPjhsNgmnNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Required Libraries**"
      ],
      "metadata": {
        "id": "DqACFp2Os3JS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03YMdCN8lkhx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from models.vgg import vgg16_bn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Parameters**"
      ],
      "metadata": {
        "id": "f1OdSJE_9t0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "in_channel = 3\n",
        "num_classes = 7\n",
        "image_shape = (224,224)\n",
        "model_checkpoint_path = \"weights/vgg/vgg_model_checkpoint.pth\""
      ],
      "metadata": {
        "id": "_8xPf-i-l7iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading model**"
      ],
      "metadata": {
        "id": "SNWZIO5nMvQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = vgg16_bn(num_classes= num_classes)\n",
        "model = torch.compile(model)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "checkpoint = torch.load(model_checkpoint_path)\n",
        "model.load_state_dict(checkpoint)"
      ],
      "metadata": {
        "id": "B2hDA9zPmiXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create folder to save images**"
      ],
      "metadata": {
        "id": "lz-ck_6P98TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_path = \"save_images\"\n",
        "\n",
        "if not os.path.exists(save_image_path):\n",
        "    os.makedirs(save_image_path)"
      ],
      "metadata": {
        "id": "EsIBzDX-l7le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting all images path**"
      ],
      "metadata": {
        "id": "eCyKPDJk-bWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_path = \"data/version1/test\"\n",
        "classes = os.listdir(test_dataset_path)\n",
        "classes.sort()\n",
        "\n",
        "images_path_list = []\n",
        "for clc in classes:\n",
        "    images_name = os.listdir(test_dataset_path + \"/\" + clc)\n",
        "    for img_name in images_name:\n",
        "        images_path_list.append(test_dataset_path + \"/\" + clc + \"/\" + img_name)\n"
      ],
      "metadata": {
        "id": "2QHEZsWT1xsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images_path_list[0:10])"
      ],
      "metadata": {
        "id": "SKsqbVGlFOy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for idx, img_path in enumerate(images_path_list):\n",
        "    img_name = os.path.basename(img_path)\n",
        "    image = cv2.imread(img_path)\n",
        "    img = image.copy()\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, image_shape)\n",
        "    \"\"\"\n",
        "      input image shape:\n",
        "        (height, width, no of channel)\n",
        "         (32, 32, 3)\n",
        "    axis (0, 1, 2)\n",
        "\n",
        "    model input shape:\n",
        "        (batch_size, no of channel, height, width)\n",
        "        (1, 3, 32, 32)\n",
        "        new axis will be (new axis, 2, 0, 1)\n",
        "    \"\"\"\n",
        "    img = np.transpose(img, (2, 0, 1))\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img/255\n",
        "    img = torch.Tensor(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_score = model(img)\n",
        "\n",
        "    _, y_pred = pred_score.max(1)\n",
        "    class_index = y_pred.item()\n",
        "    pred_class = classes[class_index]\n",
        "    actual_class = img_path.split(\"/\")[-2]\n",
        "    cv2.putText(image, actual_class, (10,10), cv2.FONT_HERSHEY_PLAIN, 1, (255,0,0), 1, cv2.LINE_AA)\n",
        "    cv2.putText(image, pred_class, (10,20), cv2.FONT_HERSHEY_PLAIN, 1, (255,0,0), 1, cv2.LINE_AA)\n",
        "\n",
        "    cv2.imwrite(save_image_path + \"/\" + img_name, image)\n",
        "\n",
        "print(\"inferencing complete\")"
      ],
      "metadata": {
        "id": "xlL_Jyym177E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-CzOcgwXyXbM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}